{
  
    
        "post0": {
            "title": "In this mini-project, we will assess major-minor axis ratio and alignment of nuclei in H&E histopathology images of Soft Tissue Leiomyosarcoma",
            "content": "import histomicstk as htk import numpy as np import scipy as sp import skimage.io import skimage.measure import skimage.color import matplotlib.pyplot as plt import matplotlib.patches as mpatches %matplotlib inline # Some nice default configuration for plots plt.rcParams[&#39;figure.figsize&#39;] = 10, 10 plt.rcParams[&#39;image.cmap&#39;] = &#39;gray&#39; titlesize = 24 . longitudinal_image_file = &#39;longitudinal.png&#39; long_im_input = skimage.io.imread(longitudinal_image_file)[:,:,:3] plt.imshow(long_im_input) _ = plt.title(&#39;Longitudinal Cellular Orientation&#39;, fontsize=16) . transverse_image_file = &#39;transverse.png&#39; trans_im_input = skimage.io.imread(transverse_image_file)[:,:,:3] plt.imshow(trans_im_input) _ = plt.title(&#39;Transverse Cellular Orientation&#39;, fontsize=16) . ref_image_file = (&#39;6070-7712.png&#39;) # L1.png im_reference = skimage.io.imread(ref_image_file)[:,:,:3] # get mean and stddev of reference image in lab space mean_ref, std_ref = htk.preprocessing.color_conversion.lab_mean_std(im_reference) . long_im_nmzd = htk.preprocessing.color_normalization.reinhard(long_im_input, mean_ref, std_ref) trans_im_nmzd = htk.preprocessing.color_normalization.reinhard(trans_im_input, mean_ref, std_ref) . plt.figure(figsize=(20, 10)) plt.subplot(1, 2, 1) plt.imshow(im_reference) _ = plt.title(&#39;Reference Image&#39;, fontsize=titlesize) plt.subplot(1, 2, 2) plt.imshow(long_im_nmzd) _ = plt.title(&#39;Normalized Longitudinal Input Image&#39;, fontsize=titlesize) . plt.figure(figsize=(20, 10)) plt.subplot(1, 2, 1) plt.imshow(im_reference) _ = plt.title(&#39;Reference Image&#39;, fontsize=titlesize) plt.subplot(1, 2, 2) plt.imshow(trans_im_nmzd) _ = plt.title(&#39;Normalized Transverse Input Image&#39;, fontsize=titlesize) . # create stain to color map stainColorMap = { &#39;hematoxylin&#39;: [0.65, 0.70, 0.29], &#39;eosin&#39;: [0.07, 0.99, 0.11], &#39;dab&#39;: [0.27, 0.57, 0.78], &#39;null&#39;: [0.0, 0.0, 0.0] } # specify stains of input image stain_1 = &#39;hematoxylin&#39; # nuclei stain stain_2 = &#39;eosin&#39; # cytoplasm stain stain_3 = &#39;null&#39; # set to null if input contains only two stains # create stain matrix W = np.array([stainColorMap[stain_1], stainColorMap[stain_2], stainColorMap[stain_3]]).T . long_im_stains = htk.preprocessing.color_deconvolution.color_deconvolution(long_im_nmzd, W).Stains # Display results plt.figure(figsize=(20, 10)) plt.subplot(1, 2, 1) plt.imshow(long_im_stains[:, :, 0]) plt.title(stain_1, fontsize=titlesize) plt.subplot(1, 2, 2) plt.imshow(long_im_stains[:, :, 1]) _ = plt.title(stain_2, fontsize=titlesize) . trans_im_stains = htk.preprocessing.color_deconvolution.color_deconvolution(trans_im_nmzd, W).Stains # Display results plt.figure(figsize=(20, 10)) plt.subplot(1, 2, 1) plt.imshow(trans_im_stains[:, :, 0]) plt.title(stain_1, fontsize=titlesize) plt.subplot(1, 2, 2) plt.imshow(trans_im_stains[:, :, 1]) _ = plt.title(stain_2, fontsize=titlesize) . # get nuclei/hematoxylin channel long_im_nuclei_stain = long_im_stains[:, :, 0] trans_im_nuclei_stain = trans_im_stains[:, :, 0] # segment foreground foreground_threshold = 60 long_im_fgnd_mask = sp.ndimage.morphology.binary_fill_holes( long_im_nuclei_stain &lt; foreground_threshold) trans_im_fgnd_mask = sp.ndimage.morphology.binary_fill_holes( trans_im_nuclei_stain &lt; foreground_threshold) # run adaptive multi-scale LoG filter min_radius = 10 max_radius = 15 long_im_log_max, long_im_sigma_max = htk.filters.shape.cdog( long_im_nuclei_stain, long_im_fgnd_mask, sigma_min=min_radius * np.sqrt(2), sigma_max=max_radius * np.sqrt(2) ) trans_im_log_max, trans_im_sigma_max = htk.filters.shape.cdog( trans_im_nuclei_stain, trans_im_fgnd_mask, sigma_min=min_radius * np.sqrt(2), sigma_max=max_radius * np.sqrt(2) ) # detect and segment nuclei using local maximum clustering local_max_search_radius = 10 long_im_nuclei_seg_mask, seeds, maxima = htk.segmentation.nuclear.max_clustering( long_im_log_max, long_im_fgnd_mask, local_max_search_radius) trans_im_nuclei_seg_mask, seeds, maxima = htk.segmentation.nuclear.max_clustering( trans_im_log_max, trans_im_fgnd_mask, local_max_search_radius) # filter out small objects min_nucleus_area = 80 long_im_nuclei_seg_mask = htk.segmentation.label.area_open( long_im_nuclei_seg_mask, min_nucleus_area).astype(np.int) trans_im_nuclei_seg_mask = htk.segmentation.label.area_open( trans_im_nuclei_seg_mask, min_nucleus_area).astype(np.int) # compute nuclei properties LongObjProps = skimage.measure.regionprops(long_im_nuclei_seg_mask) TransObjProps = skimage.measure.regionprops(trans_im_nuclei_seg_mask) print(&#39;Number of nuclei in longitudinal image = &#39;, len(LongObjProps)) print(&#39;Number of nuclei in transverse image = &#39;, len(TransObjProps)) . Number of nuclei in longitudinal image = 43 Number of nuclei in transverse image = 122 . plt.figure(figsize=(20, 10)) plt.subplot(1, 2, 1) plt.imshow(skimage.color.label2rgb(long_im_nuclei_seg_mask, long_im_input, bg_label=0), origin=&#39;lower&#39;) plt.title(&#39;Nuclei segmentation mask overlay&#39;, fontsize=titlesize) plt.subplot(1, 2, 2) plt.imshow( long_im_input ) plt.xlim([0, long_im_input.shape[1]]) plt.ylim([0, long_im_input.shape[0]]) plt.title(&#39;Nuclei bounding boxes&#39;, fontsize=titlesize) for i in range(len(LongObjProps)): c = [LongObjProps[i].centroid[1], LongObjProps[i].centroid[0], 0] width = LongObjProps[i].bbox[3] - LongObjProps[i].bbox[1] + 1 height = LongObjProps[i].bbox[2] - LongObjProps[i].bbox[0] + 1 cur_bbox = { &quot;type&quot;: &quot;rectangle&quot;, &quot;center&quot;: c, &quot;width&quot;: width, &quot;height&quot;: height, } plt.plot(c[0], c[1], &#39;g+&#39;) mrect = mpatches.Rectangle([c[0] - 0.5 * width, c[1] - 0.5 * height] , width, height, fill=False, ec=&#39;g&#39;, linewidth=2) plt.gca().add_patch(mrect) . plt.figure(figsize=(20, 10)) plt.subplot(1, 2, 1) plt.imshow(skimage.color.label2rgb(trans_im_nuclei_seg_mask, trans_im_input, bg_label=0), origin=&#39;lower&#39;) plt.title(&#39;Nuclei segmentation mask overlay&#39;, fontsize=titlesize) plt.subplot(1, 2, 2) plt.imshow( trans_im_input ) plt.xlim([0, trans_im_input.shape[1]]) plt.ylim([0, trans_im_input.shape[0]]) plt.title(&#39;Nuclei bounding boxes&#39;, fontsize=titlesize) for i in range(len(TransObjProps)): c = [TransObjProps[i].centroid[1], TransObjProps[i].centroid[0], 0] width = TransObjProps[i].bbox[3] - TransObjProps[i].bbox[1] + 1 height = TransObjProps[i].bbox[2] - TransObjProps[i].bbox[0] + 1 cur_bbox = { &quot;type&quot;: &quot;rectangle&quot;, &quot;center&quot;: c, &quot;width&quot;: width, &quot;height&quot;: height, } plt.plot(c[0], c[1], &#39;g+&#39;) mrect = mpatches.Rectangle([c[0] - 0.5 * width, c[1] - 0.5 * height] , width, height, fill=False, ec=&#39;g&#39;, linewidth=2) plt.gca().add_patch(mrect) . LongObjPropsTable = skimage.measure.regionprops_table(long_im_nuclei_seg_mask, properties=(&#39;label&#39;, &#39;orientation&#39;, &#39;major_axis_length&#39;, &#39;minor_axis_length&#39;,) ) . TransObjPropsTable = skimage.measure.regionprops_table(trans_im_nuclei_seg_mask, properties=(&#39;label&#39;, &#39;orientation&#39;, &#39;major_axis_length&#39;, &#39;minor_axis_length&#39;) ) . long_orientation = LongObjPropsTable[&#39;orientation&#39;] trans_orientation = TransObjPropsTable[&#39;orientation&#39;] . _ = plt.hist(long_orientation) plt.show() . _ = plt.hist(trans_orientation) plt.show() . LongObjPropsTable[&#39;minor_axis_length&#39;] . array([17.82988548, 26.57283721, 32.62511918, 17.9561122 , 24.04859764, 25.90507908, 40.4939446 , 35.97834554, 22.36994041, 14.45953977, 40.12733974, 21.8516542 , 12.42029426, 23.54320991, 20.64609371, 24.50122929, 31.37118343, 23.3645544 , 18.90967646, 28.31049082, 27.86635531, 15.762809 , 32.84102401, 31.56465618, 18.39091073, 39.147678 , 24.17782857, 20.93425473, 24.76587761, 34.92536675, 33.35863685, 23.92101848, 25.98666127, 30.92181968, 17.00492511, 27.91541626, 44.926728 , 16.78490142, 54.96896025, 28.69640483, 20.71021864, 16.72920149, 18.5068537 ]) .",
            "url": "https://https//jamcron.github.io//research_blog/2021/12/17/Nuclei_Orientation.html",
            "relUrl": "/2021/12/17/Nuclei_Orientation.html",
            "date": " • Dec 17, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Plot Tumor Differentiation Score Analysis",
            "content": "%matplotlib inline import matplotlib.pyplot as plt; plt.rcdefaults() import numpy as np import matplotlib.pyplot as plt SMALL_SIZE = 8 MEDIUM_SIZE = 10 BIGGER_SIZE = 12 scores = [&#39;1&#39;, &#39;2&#39;, &#39;3&#39;] missed = [0.123287671232877, 0.125933267261315, 0.003718728870859] plt.bar(scores, missed) plt.ylabel(&quot;Error Rate&quot;) plt.xlabel(&quot;Tumor Differentiation Score&quot;) plt.title(&quot;Error rates by Tumor Differentiation Score&quot;) # plt.rc(&#39;font&#39;, size=SMALL_SIZE) # controls default text sizes # plt.rc(&#39;axes&#39;, titlesize=SMALL_SIZE) # fontsize of the axes title # plt.rc(&#39;axes&#39;, labelsize=MEDIUM_SIZE) # fontsize of the x and y labels # plt.rc(&#39;xtick&#39;, labelsize=SMALL_SIZE) # fontsize of the tick labels # plt.rc(&#39;ytick&#39;, labelsize=SMALL_SIZE) # fontsize of the tick labels # plt.rc(&#39;legend&#39;, fontsize=SMALL_SIZE) # legend fontsize # plt.rc(&#39;figure&#39;, titlesize=BIGGER_SIZE) # fontsize of the figure title plt.show() . %matplotlib inline import matplotlib.pyplot as plt; plt.rcdefaults() import numpy as np import matplotlib.pyplot as plt SMALL_SIZE = 8 MEDIUM_SIZE = 10 BIGGER_SIZE = 12 scores = [&#39;1&#39;, &#39;2&#39;, &#39;3&#39;] missed = [368/3869, 1114/15135, 0/2958] plt.bar(scores, missed) plt.ylabel(&quot;Error Rate&quot;) plt.xlabel(&quot;Tumor Differentiation Score&quot;) plt.title(&quot;Error Rates by Tumor Differentiation Score&quot;, fontsize=14, fontweight=1000 ) # plt.rc(&#39;font&#39;, size=SMALL_SIZE) # controls default text sizes # plt.rc(&#39;axes&#39;, titlesize=SMALL_SIZE) # fontsize of the axes title # plt.rc(&#39;axes&#39;, labelsize=MEDIUM_SIZE) # fontsize of the x and y labels # plt.rc(&#39;xtick&#39;, labelsize=SMALL_SIZE) # fontsize of the tick labels # plt.rc(&#39;ytick&#39;, labelsize=SMALL_SIZE) # fontsize of the tick labels # plt.rc(&#39;legend&#39;, fontsize=SMALL_SIZE) # legend fontsize # plt.rc(&#39;figure&#39;, titlesize=BIGGER_SIZE) # fontsize of the figure title plt.show() . Plot normal tissue structure analysis . import pandas as pd from matplotlib import pyplot as plt data = [[&#39;Smooth Muscle&#39;, 0.147, 0.681], [&#39;Fibroblasts &amp; Collagen&#39;, 0.825, 0.639], [&#39;Adipose&#39;, 0.233, 0.032], # [&#39;Inflammatory Aggregates&#39;, 0.041, 0.084], # [&#39;Arteries&#39;, 0.127, 0.065], #[&#39;Veins &amp; Lymphatics&#39;, 0.080, 0.155] ] df = pd.DataFrame(data, columns = [&#39;Tissue Structure&#39;, &#39;Correctly Classified as Normal (n=464)&#39;, &#39;Incorrectly Classified as Tumor (n=476)&#39; ] ) print(df) df.plot(x = &quot;Tissue Structure&quot;, y = [&#39;Correctly Classified as Normal (n=464)&#39;,&#39;Incorrectly Classified as Tumor (n=476)&#39;], kind= &#39;bar&#39;, figsize=(10,7) ) plt.title(&quot;Normal Tissue Structure Analysis&quot;, fontsize=20, fontweight=1000) plt.ylabel(&quot;Percentage of Tiles Containing the Histologic Feature&quot;, fontsize=14, rotation=90) plt.xlabel(None) plt.xticks(rotation=0, fontsize=14) plt.legend(prop={&#39;size&#39;:11.5}) plt.show() . Tissue Structure Correctly Classified as Normal (n=464) 0 Smooth Muscle 0.147 1 Fibroblasts &amp; Collagen 0.825 2 Adipose 0.233 Incorrectly Classified as Tumor (n=476) 0 0.681 1 0.639 2 0.032 . Plot confusion matrix for tumor v. normal classifier . from mlxtend.plotting import plot_confusion_matrix . Actual_tumor_predicted_tumor = 16557 Actual_tumor_predicted_normal = 765 Actual_normal_predicted_normal = 3855 Actual_normal_predicted_tumor = 703 . fig, ax = plot_confusion_matrix(conf_mat=conf_matrix, figsize=(6, 6), cmap=plt.cm.Greens) plt.xlabel(&#39;Predictions&#39;, fontsize=18) plt.ylabel(&#39;Actuals&#39;, fontsize=18) plt.title(&#39;Confusion Matrix&#39;, fontsize=18) plt.show() . from mlxtend.evaluate import confusion_matrix cm =cm = confusion_matrix(y_target=targ_list, y_predicted=pred_list) cm import matplotlib.pyplot as plt from mlxtend.plotting import plot_confusion_matrix fig, ax = plot_confusion_matrix(conf_mat=cm) plt.show() . NameError Traceback (most recent call last) &lt;ipython-input-1-2c1f8f1a1481&gt; in &lt;module&gt; 1 from mlxtend.evaluate import confusion_matrix 2 -&gt; 3 cm =cm = confusion_matrix(y_target=targ_list, 4 y_predicted=pred_list) 5 cm NameError: name &#39;targ_list&#39; is not defined . diagram . # from matplotlib import pyplot as plt # data = [[&#39;Smooth Muscle&#39;, &#39;Correct classification&#39;, 0.147], # [&#39;Smooth Muscle&#39;, &#39;Misclassification&#39;, 0.681], # [&#39;Adipose&#39;, &#39;Correct classification&#39;, 0.233], # [&#39;Adipose&#39;, &#39;Misclassification&#39;, 0.032], # [&#39;Fibroblasts &amp; Collagen&#39;, &#39;Correct classification&#39;, 0.825], # [&#39;Fibroblasts &amp; Collagen&#39;, &#39;Misclassification&#39;, 0.639], # [&#39;Inflammatory Aggregates&#39;, &#39;Correct classification&#39;, 0.041], # [&#39;Inflammatory Aggregates&#39;, &#39;Misclassification&#39;, 0.084], # [&#39;Arteries&#39;, &#39;Correct classification&#39;, 0.127], # [&#39;Arteries&#39;, &#39;Misclassification&#39;, 0.065], # [&#39;Veins &amp; Lymphatics&#39;, &#39;Correct classification&#39;, 0.080], # [&#39;Veins &amp; Lymphatics&#39;, &#39;Misclassification&#39;, 0.155] # ] from mlxtend.evaluate import confusion_matrix cm =cm = confusion_matrix(y_target=targ_list, y_predicted=pred_list) cm import matplotlib.pyplot as plt from mlxtend.plotting import plot_confusion_matrix fig, ax = plot_confusion_matrix(conf_mat=cm) plt.show() # df = pd.DataFrame(data, columns = [&#39;Tissue Structure&#39;, &#39;Prediction&#39;, &#39;Frequency&#39;]) # df # df.plot(x = &quot;Tissue Structure&quot;, # y = [&#39;Prediction&#39;,&#39;Frequency&#39;], # kind= &#39;bar&#39;, # figsize=(9,8) # # ) # plt.show() # # colors = {&#39;Correct classification&#39;:&#39;green&#39;, &#39;Misclassification&#39;:&#39;blue&#39;} # c = data[&#39;Prediction&#39;].apply(lambda x: colors[x]) # df.plot(x=&quot;Tissue Structure&quot;, y=[&#39;Prediction&#39;,&quot;Frequency&quot;], kind=&quot;bar&quot;) # bars = plt.bar(x=data[&#39;Tissue Structure&#39;], y=[data[&#39;Frequency&#39;], str(data[&#39;Prediction&#39;])], color=c, label=colors, # height=1) # labels = list(colors.keys()) # handles = [plt.Rectangle((0,0),1,1, color=colors[label]) for label in labels] # plt.legend(handles, labels) .",
            "url": "https://https//jamcron.github.io//research_blog/2021/12/16/Plots_and_Figs.html",
            "relUrl": "/2021/12/16/Plots_and_Figs.html",
            "date": " • Dec 16, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "nbdev + GitHub Codespaces: A New Literate Programming Environment",
            "content": "Today, we are going to show you how to set up a literate programming environment, allowing you to use an IDE (VS Code) and an interactive computing environment (Jupyter), without leaving your browser, for free, in under 5 minutes. You’ll even see how VSCode and Jupyter work together automatically! But first, what is literate programming? And how did I go from skeptic to a zealot of literate programming? . Introduction . Literate programming is a programming paradigm introduced by Donald Knuth in which a computer program is given an explanation of its logic in a natural language, such as English, interspersed with snippets of macros and traditional source code, from which compilable source code can be generated. According to Knuth, literate programming provides higher-quality programs by forcing programmers to explicitly state the thoughts behind the program. This process makes poorly thought-out design decisions more obvious. Knuth also claims that literate programming provides a first-rate documentation system, which is not an add-on, but is grown naturally in the process of exposition of one’s thoughts during a program’s creation. 1 . When I first learned about literate programming, I was quite skeptical. For the longest time, I had wrongly equated Jupyter notebooks with literate programming. Indeed, Jupyter is a brilliant interactive computing system, which was awarded the Association of Computing Machinery (ACM) Software System Award, and is loved by many developers. However, Jupyter falls short of the literate programming paradigm for the following reasons:2 . It can be difficult to compile source code from notebooks. | It can be difficult to diff and use version control with notebooks because they are not stored in plain text. | It is not clear how to automatically generate documentation from notebooks. | It is not clear how to properly run tests suites when writing code in notebooks. | . My skepticism quickly evaporated when I began using nbdev, a project that extends notebooks to complete the literate programming ideal. I spent a month, full time, using nbdev while contributing to the python library fastcore, and can report that Donald Knuth was definitely onto something. The process of writing prose and tests alongside code forced me to deeply understand why the code does what it does, and to think deeply about its design. Furthermore, the reduced cognitive load and speed of iteration of having documentation, code, and tests in one location boosted my productivity to levels I have never before experienced as a software developer. Furthermore, I found that developing this way bolstered collaboration such that code reviews not only happened faster but were more meaningful. In short, nbdev may be the most profound productivity tool I have ever used. . As a teaser, look how easy it is to instantiate this literate programming environment, which includes a notebook, a docs site and an IDE with all dependencies pre-installed! :point_down: . . Features of nbdev . As discussed in the docs, nbdev provides the following features: . Searchable, hyperlinked documentation, which can be automatically hosted on GitHub Pages for free. | Python modules, following best practices such as automatically defining __all__ with your exported functions, classes, and variables. | Pip and Conda installers. | Tests defined directly in notebooks which run in parallel. This testing system has been thoroughly tested with GitHub Actions. | Navigate and edit your code in a standard text editor or IDE, and export any changes automatically back into your notebooks. | . Since you are in a notebook, you can also add charts, text, links, images, videos, etc, that are included automatically in the documentation of your library, along with standardized documentation generated automatically from your code. This site is an example of docs generated automatically by nbdev. . GitHub Codespaces . Thanks to Conda and nbdev_template, setting up a development environment with nbdev is far easier than it used to be. However, we realized it could be even easier, thanks to a new GitHub product called Codespaces. Codespaces is a fully functional development environment in your browser, accessible directly from GitHub, that provides the following features: . A full VS Code IDE. | An environment that has files from the repository mounted into the environment, along with your GitHub credentials. | A development environment with dependencies pre-installed, backed by Docker. | The ability to serve additional applications on arbitrary ports. For nbdev, we serve a Jupyter notebook server as well as a Jekyll based documentation site. | A shared file system, which facilitates editing code in one browser tab and rendering the results in another. | … and more. | Codespaces enables developers to immediately participate in a project without wasting time on DevOps or complicated setup steps. Most importantly, CodeSpaces with nbdev allows developers to quickly get started with creating their own software with literate programming. . A demo of nbdev + Codespaces . This demo uses the project fastai/fastcore, which was built with nbdev, as an example. First, we can navigate to this repo and launch a Codespace: . . If you are launching a fresh Codespace, it may take several minutes to set up. Once the environment is ready, we can verify that all dependencies we want are installed (in this case fastcore and nbdev): . . Additionally, we can serve an arbitrary number of applications on user-specified ports, which we can open through VSCode as shown below: . . In this case, these applications are a notebook and docs site. Changes to a notebook are reflected immediately in the data docs. Furthermore, we can use the cli command nbdev_build_lib to sync our notebooks with python modules. This functionality is shown below: . . This is amazing! With a click of a button, I was able to: . Launch an IDE with all dependencies pre-installed. | Launch two additional applications: a Jupyter Notebook server on port 8080 and a docs site on port 4000. | Automatically update the docs and modules every time I make a change to a Jupyter notebook. | This is just the tip of the iceberg. There are additional utilities for writing and executing tests, diffing notebooks, special flags for hiding, showing, and collapsing cells in the generated docs, as well as git hooks for automation. This and more functionality is covered in the nbdev docs. . Give It A Try For Yourself . To try out nbdev yourself, take this tutorial, which will walk you through everything you need to know. The tutorial also shows you how to use a repository template with the configuration files necessary to enable Codespaces with nbdev. . You Can Write Blogs With Notebooks, Too! . This blog post was written in fastpages which is also built on nbdev! We recommend fastpages if you want an easy way to blog with Jupyter notebooks. . Additional Resources . The GitHub Codepaces site. | The official docs for Codespaces. | The nbdev docs. | The nbdev GitHub repo. | fastpages: The project used to write this blog. | The GitHub repo fastai/fastcore, which is what we used in this blog post as an example. | . Wikipedia article: Literate Programming &#8617; . | This is not a criticism of Jupyter. Jupyter doesn’t claim to be a full literate programming system. However, people can sometimes (unfairly) judge Jupyter according to this criteria. &#8617; . |",
            "url": "https://https//jamcron.github.io//research_blog/codespaces",
            "relUrl": "/codespaces",
            "date": " • Dec 10, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://https//jamcron.github.io//research_blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://https//jamcron.github.io//research_blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}